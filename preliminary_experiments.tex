\chapter{Preliminary Experiments}\label{sec:pe}
    \section{Background}\label{sec:pa_s}
	Our visual matching task (described in detail under section~\ref{sec:m_bt}) relies on both emotion and pattern recognition.
	As luminosity variations could greatly disturb our pupillary measurements, we need equally luminous images in all conditions.
	In this thesis we are employing a novel feature-obfuscation algorithm, Pyxrand \citep{pyxrand}, which allows us to process the same images we use for emotion recognition and use them as pattern recognition templates - the algorithm is more accurately described under section~\ref{sec:m_vs_si}.
	
	In order to make better informed decisions in our methods section (chapter~\ref{sec:m}) we are performing a series of preliminary experiments whereby we determine how various parameters of our image processing script impact reaction times and error rates.
    \section{Focus}
	The parameters whose effect on reaction times and error rates we shall test are the following:
	\begin{itemize}
	    \item Scrambling type (our script provides both cluster-based and kernel-based scrambling, functions which we explicitly detail under section~\ref{sec:m_vs_si}).
	    \item Scrambling resolution.
	\end{itemize}
	The information which we try to extract from combinations of the above is:
	\begin{itemize}
	    \item What scrambling kind and resolution provide for equally fast performance in pattern recognition trials as in our easy and hard emotion recognition trials (see section~\ref{sec:m_vs_ef} for information on our emotional images).
	    \item What scrambling kind and resolution provide for equally accurate performance in pattern recognition trials as in our easy and hard emotion recognition trials.
	\end{itemize}

    \section{Methods}
	\subsection{Participants}
	    Participants were recruited from staff at the Central Institute of Mental Health, and students of the Universities of Mannheim and Heidelberg.
	    Since these are preparatory trials we opted for merely around 7 participants per run.
	    Participants are identified in the study by a 2-letter code, and a subset of them have participated in multiple runs of our preliminary trials.
	    It should be noted that runs are therefore not well suited for direct comparison or for binning; but they do offer a good predictor for expected variability in reaction times.
	\subsection{Behavioural Test}
	    For stimulus presentation and data acquisition in these experiments we used faceRT \citep{faceRT}, a Python script written for the purpose of this thesis and openly published on GitHub \citep{github}.
	    Our script uses the PsychoPy suite \citep{Peirce2008} for specialized, high-precision stimulus rendering and timing.
	    
	    The behavioural test was done in accordance with the guidelines for our main experiment run (specified under section~\ref{sec:m_bt}).
	    We have varied some of the parameters over our preliminary trials:
	    \subsubsection{Simple Cluster-Based Scrambling}\label{sec:pe_m_bt_ss}
		The stimulus presentation protocol used for these trials is revision \textcolor{lg}{ce2b3a8f30} of the faceRT \citep{faceRT} script suite.
		Stimuli were presented fully randomized per-participant, and stimulus sequences were compiled manually, following the listed requirements:
		\begin{itemize}
		    \item Each condition should have 10 corresponding trials (conditions are: emotion \{happy; afraid\} $\times$ emotion intensity \{40\%; 100\%\}; and emotion \{happy; afraid\} $\times$ scrambling \{6; 10; 14; 18; 22; 26\}) - yielding a total of 160 trials.
		    \item The same person's face (even with a different emotion) should not appear more than once in one slide.
		    \item Each face picture should appear no more than 3 times in the entire experiment.
		\end{itemize}
		To better determine the appropriate response window duration for further trials, we have decided on a conservative duration of \SI{5}{\second}.
	    \subsubsection{Composite Kernel-and-Cluster-Based Scrambling}\label{sec:pe_m_bt_cs}
		Here the stimulus sequence was re-written in a more automated and reliable manner.
		The automation was done via the sequence-calculation software, Pystim \citep{pystim} - a Python script written for the purpose of this thesis and openly published on GitHub.
		The requirements followed and met by the script are:
		\begin{itemize}
		    \item Each emotional picture should be presented once as the template (emotion defining) figure, once as a target, and once as a distractor.
		    \item Trial repeat number for each scrambling severity and emotional concentration should be equal
		    \item The same person's face (even with a different emotion) should not appear more than once in any one emotion-recognition trial.
		\end{itemize}
		The decision to show all emotional images an equal number of times and present each one as the template lead to a total increase of the trial count
		(8 faces $\times$ 2 genders $\times$ 2 emotions $\times$ 2 intensities \textit{plus} 8 faces $\times$ 2 genders $\times$ 2 emotions $\times$ 6 intensities yields 256 trials as opposed to the 160 resulting from the stimulus sequence in section~\ref{sec:pe_m_bt_ss}).
		To limit fatigue experienced by our participants we have decided to only test 5 scrambling cell steps at a time (reducing the trial number to 224).
		
		Additionally, to constrain test duration and relieve fatigue for our participants we have decided to provide a response window of \SI{4}{\second}.
		This somewhat undershoots the recommended value from section~\ref{sec:pe_r_ss}.
		In light of the necessity to reduce test duration and in light of acquisition time considerations further detailed in section~\ref{sec:m_fmri}, we have - however - decided that this is a fair trade-off.
	\subsection{Stimulus Images}\label{sec:pe_m_si}
	    \subsubsection{Simple Cluster-Based Scrambling}
		In a first set of trials we have scrambled images with scrambling clusters of sizes starting at \SI{6}{\pixel} and progressing to \SI{26}{\pixel} in \SI{4}{\pixel} steps.
	    \subsubsection{Composite Kernel-and-Cluster-Based Scrambling}\label{sec:pe_m_si_cs}
		As the previous set-up of preliminary experiments proved unsatisfactory due to eye visibility (which is known to elicit fearful emotional reactions \citep{Whalen2004} that could well disrupt our brain imaging baseline), we decided to further obfuscate facial features.
		This was done by kernel-scrambling the images (as detailed in section~\ref{sec:m_vs_si_kbs}) before applying the same cluster-based scrambling as in the experiments mentioned above.
		Such a preparation of the images renders all features with a horizontal and/or vertical spatial frequency above $\frac{1}{\sigma_{K}}$ (where $\sigma_{K}$ is the pixel redistribution standard deviation demonstratively calculated in figure~\ref{eq:lrgn}) unrecognisable.
		
		The transition from the black of the pupil over the iris to the white of the cornea in our stimulus images averages around \SI{8}{\pixel} (based on manual analysis).
		We therefore experimented with a series of kernel-based scrambling steps around that value.
		
		We found that for smaller scrambling kernels, the spatial frequency low-pass cut-off was too low (as seen in in figures \ref{fig:m_vs_pe_1_a} and \ref{fig:m_vs_pe_1_b} where the eyes are still visible).
		We also found that for the \SI{8}{\pixel} scrambling kernel, the subsequent cluster-based scrambling includes very many clusters with predominantly background patches (as seen in figure~\ref{fig:m_vs_pe_1_d})
		This happens because as the scrambling kernel becomes larger face-pixels diffuse further into the background forming a sparsely populated halo which still has to be included to preserve pixel consistency.
		
		For the \SI{6}{\pixel} kernel we found that the eyes were still recognisable in the picture which had not yet undergone cluster-based scrambling, but became unrecognisable after cluster-based scrambling.
		The recognition of the eyes in the first image of figure~\ref{fig:m_vs_pe_1_c} relies on contextual information from other low-frequency features.
		When the image is scrambled on a cluster basis, a second high-pass cut-off takes place - 
		after which only features with a vertical and/or horizontal spatial frequency strictly above $\frac{1}{\SI{26}{\pixel}}$ (\SI{26}{\pixel} being the cluster height and width) can be distinguished.
		With the contextual information from other features such as brows and nose gone, the pupil, the iris, and adjacent portions of the eyelids only look like a dark blob.
		Based on these tests we have decided to use faces pre-scrambled with a kernel of \SI{6}{\pixel} for the second round of reaction time testing.
		
		\begin{figure}
		    \begin{subfigure}[b]{0.495\textwidth}
			\centering\scalebox{0.3}{\includegraphics{./img/01F_FE_C100_px2rand.jpg} \includegraphics{./img/01F_FE_C100_px2rand_cell26rand.jpg}}
			\subcaption{\SI{2}{\pixel} scrambling kernel}
			\label{fig:m_vs_pe_1_a}
		    \end{subfigure}
		    ~%add desired spacing between images, e. g. ~, \quad, \qquad etc. (or a blank line to force the subfigure onto a new line)
		    \begin{subfigure}[b]{0.495\textwidth}
			\centering\scalebox{0.3}{\includegraphics{./img/01F_FE_C100_px4rand.jpg} \includegraphics{./img/01F_FE_C100_px4rand_cell26rand.jpg}}
			\subcaption{\SI{4}{\pixel} scrambling kernel}
			\label{fig:m_vs_pe_1_b}
		    \end{subfigure}
		    
		    \vspace{0.5cm}%add desired spacing between images, e. g. ~, \quad, \qquad etc. (or a blank line to force the subfigure onto a new line)
		    \begin{subfigure}[b]{0.495\textwidth}
			\centering\scalebox{0.3}{\includegraphics{./img/01F_FE_C100_px6rand.jpg} \includegraphics{./img/01F_FE_C100_px6rand_cell26rand.jpg}}
			\subcaption{\SI{6}{\pixel} scrambling kernel}
			\label{fig:m_vs_pe_1_c}
		    \end{subfigure}
		    ~%add desired spacing between images, e. g. ~, \quad, \qquad etc. (or a blank line to force the subfigure onto a new line)
		    \begin{subfigure}[b]{0.495\textwidth}
			\centering\scalebox{0.3}{\includegraphics{./img/01F_FE_C100_px8rand.jpg} \includegraphics{./img/01F_FE_C100_px8rand_cell26rand.jpg}}
			\subcaption{\SI{8}{\pixel} scrambling kernel}
			\label{fig:m_vs_pe_1_d}
		    \end{subfigure}
		    \caption{Kernel-based scrambling of faces followed by composite (kernel-based and then cluster-based) scrambling of the same faces. 
		    The kernels are ascending in size; images were prepared via Pyxrand\citep{pyxrand} (revision \textcolor{lg}{1eb1f7cd65}).}
		    \label{fig:m_vs_pe_1}
		\end{figure}
	\subsection{Data Post-Processing}
	    Our data analysis script handles system flaws in reaction time recording (whereby negative reaction times are printed) by replacing the value with the median of the category of interest which the trial is part of.
	    These categories are defined by the nature of the presented stimulus - “emotional easy”, “emotional hard”, and “scrambled X” with X being any of the scrambling cluster sizes tested in each run of the experiment.
	    It should be noted that such errors appear only very rarely (at most twice in a measurement), so this slight manipulation via the most outlier-resistant predictor should impact the data in no other way than assuring its viability for statistical methods requiring full datasets.  
    \section{Results}\label{sec:pe_r}
	In the following experiments we examine reaction times and error rates for the recognition of progressively scrambled images in comparison to the recognition of our two emotional concentrations.
	The reaction time figures which we present include both per-participant and population sample bar plots (the latter marked as “ALL”).
	\subsection{Cluster-Based Scrambling}\label{sec:pe_r_ss}
	    For the results presented in figure~\ref{fig:r_pe_ss1} we have used a simple cluster-based scrambling algorithm and a hand-written balanced stimulus sequence 
	    (detailed in sections~\ref{sec:pe_m_si} and~\ref{sec:pe_m_bt_ss}).
	    \py[pe_ss1]{fig_pe_ss1}
	    
	    Figure~\ref{fig:r_pe_ss1} shows that reaction times for the difficult emotion recognition condition are significantly different from (one-tailed related sample t-test \textit{p}-value of 
	    \py[pe_ss1]{tex_nr(ttest_rel(data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 40)]['RT'], data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 100)]['RT'])[1]/2)}),
	    and higher than for the easy condition.
	    The results also indicate the presence of a downward trend in reaction times over increasing scrambling cluster sizes.
	    Additionally we see the emergence of a plateau-phase over higher scrambling cluster sizes.
	    
	    To test the validity of our tentative interpretation regarding a plateau phase, we have fitted a mixed model to the reaction times of pattern recognition trials.
	    The model presented in table~\ref{tab:r_pe_ss1} supports this interpretation by showing that:
	    \begin{itemize}
		\item There is a negative progression among the first three factors, with all factor values lying outside of the confidence intervals of all others.
		\item For the subsequent 4 factors there is no obvious trend, with all factor values lying within each other's confidence intervals. 
	    \end{itemize}
	    \py[pe_ss1]{lm(data=data_pe_ss1[(data_pe_ss1['scrambling'] != 0)], fixed='RT~CoI', random='ID', title='Mixed model fitted to the raw data depicted in figure~\\ref{fig:r_pe_ss1}. Our factors are the conditions of interest (CoI), excluding the emotion recognition trials. The mod el chooses the first factor (scrambling-06) as the base intercept. Note the downwards trend for the first 3 factors and that the last 4 factors\' values lie within each other\'s confidence intervals.', label='tab:r_pe_ss1')}

	    As we can see in table~\ref{tab:r_pe_ss2} pattern recognition of figures produced with a \SI{6}{\pixel} scrambling cluster recommends itself as the least unlikely (to keep with accurate terminology of the hypothesis testing we are performing) condition to share an equivalent baseline with difficult emotion recognition.
	    Similarly, it is pattern recognition of images processed with a \SI{22}{\pixel} scrambling cluster which we choose as our best-guess reaction time equivalent for easy emotion recognition.
	    \py[pe_ss1]{p_table(data_pe_ss1, ['CoI', 'emotion-easy', 'emotion-hard'], ['scrambling', 6, 10, 14, 18, 22, 26], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Two-tailed paired sample t-test \\textit{p}-values for the data in figure~\\ref{fig:r_pe_ss1}; testing the probability of our measured observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_ss2')}
	    
	    In addition to the reaction time per-category analysis, we attempted to gauge the maximal window for reaction times which we should provide in further experiments.
	    For this analysis we have selectively looked at reaction times for images processed with \SI{0}{\pixel}, \SI{6}{\pixel}, and \SI{22}{\pixel} scrambling clusters (due to considerations detailed above and documented in table~\ref{tab:r_pe_ss2}).
	    \py{fig_pe_ss2}
	    
	    Figure~\ref{fig:r_pe_ss2} shows the reaction time distribution for the said subset of trials.
	    The mean value ($\mu$) for the reaction times is approximately \pySI{np.around(data_pe_ss2['RT'].mean(), decimals=2)}{\second}, 
	    and the standard deviation ($\sigma$) of the fitted normal distribution is approximately \pySI{np.around(np.std(data_pe_ss2['RT']), decimals=2)}{\second}.
	    Based on the three-sigma rule (see figure~\ref{eq:3s} for a general expression) we have decided that a reaction time cut-off of \pySI{np.around(data_pe_ss2['RT'].mean()+3*np.std(data_pe_ss2['RT']), decimals=2)}{\second} should not statistically distort our data.
	    
	    We have also tried to analyse the error rates in our Hariri-style matching task in order to extract more information on the appropriateness of our proposed baselines.
	    The results herefor are presented in figure~\ref{fig:r_pe_ss3}.
	    The data presented therein shows a constant null error rate for easy emotion recognition.
	    \py[pe_ss3]{fig_pe_ss3}
	    	    
	    To test whether error rates for this one condition are indeed significantly different we have performed an ANOVA (see table~\ref{tab:r_pe_ss3}).
	    The value lies considerably above the popular significance threshold of \textit{p}<0.05, indicating that the data does not support our tentative interpretation.
	\subsection{Composite (Kernel-and-Cluster-Based) Scrambling}\label{sec:pe_r_cs}
	    Based on the results presented in section~\ref{sec:pe_r_ss} we have performed additional experiments using a series of improved method choices (detailed in sections~\ref{sec:pe_m_si_cs} and~\ref{sec:pe_m_bt_cs}).
	    
	    We have re-run experiments with kernel-and-cluster scrambled images a number of times.
	    This was based on progressively noticing parameters in need of adjustment so as to create a most faithful emulation of the in-scanner visual experience.
	    For the sake of brevity, we will only discuss the results of our final and most faithful emulation here in this section.
	    Data from the previous runs is appended for the sake of completion under section~\ref{sec:sm_ndper}.
	     
	    \py[pe_cs3]{fig_pe_cs3} 
	    
	    Figure~\ref{fig:r_pe_cs3} presents the the data from the final preliminary experiment run - which best approximates the visual input participants will be receiving in the fMRI trials, and which we trust above all others as an appropriate guideline for further experimental choices.
	    Here we present the standard deviation graphically alongside the standard error of the mean to better illustrate the true variability of our reaction times.
	    An obvious feature of this graphic is the disappearance of the plateau phase, which we have previously observed; this is only partly corroborated by other test runs, as seen in supplementary figures~\ref{fig:r_pe_cs1} and~\ref{fig:r_pe_cs2}).
	    
	    We have tried to determine the best-guess equivalent for our categories of interest - in terms of reaction times - using a t-test \textit{p}-value listing (see table~\ref{tab:r_pe_cs3}).
	    Our results indicate that pattern recognition of figures produced with a \SI{11}{\pixel} scrambling cluster is the least unlikely condition to share an equivalent baseline with difficult emotion recognition.
	    Similarly, it is pattern recognition of images processed with a \SI{23}{\pixel} scrambling cluster which is the best-guess reaction time equivalent for easy emotion recognition.
	    \py[pe_cs3]{p_table(data_pe_cs3, ['CoI', 'emotion-easy', 'emotion-hard'], ['scrambling', 11, 15, 19, 23, 27], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Table of two-tailed paired sample t-test \\textit{p}-values for the data in figure ~\\ref{fig:r_pe_cs3}, testing the probability of our observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_cs3')}
	    
	    \py[pe_cs5]{fig_pe_cs5}
	    
	    To re-examine potential weaknesses of our baseline concept (related to error rate distribution and further discussed in section~\ref{sec:pe_r_ss}), we have also analysed error rates for this last and methodologically most faithful preliminary experiment run.
	    Figure~\ref{fig:r_pe_cs5} presents a slightly divergent picture from what we have seen in figure~\ref{fig:r_pe_ss3}.
	    For one thing, the easy emotion recognition condition no longer has a null error rate.
	    This time, however, there is a significant error rate divergence for one of our conditions compared to all of the others (as seen in figure~\ref{fig:r_pe_cs5}, and verified in table~\ref{tab:r_pe_cs5}).
	    \py[pe_cs5]{av(data_pe_cs5, 'ER~CoI+Error(ID)', title='One-way repeated measure ANOVA table for the data depicted in figure~\\ref{fig:r_pe_cs5}. The $Pr(>F)$ value indicates the adjusted probability of observed results occurring by chance if the means of our defined categories are equal.', label='tab:r_pe_cs5')}
	
	    We also analyse whether our reaction time window could constrain our data.
	    In figure~\ref{fig:r_pe_cs4} we see that reaction times seem to fade approximately \SI{0.5}{\second} before our cut-off, and the fitted normal distribution does not indicate expected results beyond that point.
	    \py[pe_cs4]{fig_pe_cs4}
	    
    \section{Discussion}\label{sec:pe_d}
	\subsection{Final Model Quality Assessment}\label{sec:pe_d_fm}
	    We have decided to fit a mixed model to both the reaction times and error rates of our last-run data in order to check the quality of the baseline we have proposed as the best-guess solution based on the data detailed above.
	    For this model we are defining “scrambling” and “difficulty” as our factors of interest (independent variables).
	    Easy emotion recognition and its corresponding pattern recognition variant (\SI{6}{\pixel} kernel- and \SI{23}{\pixel} cluster-scrambled) are defined as easy,
	    while hard emotion recognition and its corresponding pattern recognition variant (\SI{6}{\pixel} kernel- and \SI{11}{\pixel} cluster-scrambled) are defined as hard.
	    
	    For our ideal baseline we would be expecting a null value for the scrambling factor and a positive value for the difficulty factor in the reaction time model.
	    In the error rate model we would be expecting a null value for the scrambling factor and either a null or positive value for the difficulty factor.
	    
	    Tables~\ref{tab:r_pe_cs5s} and~\ref{tab:r_pe_cs3s}, provide a succinct and reliable validation for our proposed baseline model.
	    
	    Table~\ref{tab:r_pe_cs5s} recommends the choice of scrambling as a suitable baseline creation method for our task.
	    The factor determined for this dimension is null, meaning that scrambling does not compromise the behavioural equivalence of emotional testing and baseline trials.
	    Difficulty does also not seem to impact the error rate, which we consider fortunate, though a higher error rate for difficult trials would also have been acceptable.
	    The interaction effect of difficulty and scrambling is probably an effect of the deviating hard emotion recognition category we have observed under figure~\ref{fig:r_pe_cs5}, with an inverted balance due to our model's choice of a base intercept.
	    \py[pe_cs5]{lm(data=data_pe_cs5[(data_pe_cs5['CoI'] == 'scrambling-11') | (data_pe_cs5['CoI'] == 'scrambling-23') | (data_pe_cs5['CoI'] == 'emotion-hard') | (data_pe_cs5['CoI'] == 'emotion-easy')], fixed='ER~difficulty*scrambled', random='ID', title='Mixed model fitted to the raw error rate data depicted in figure~\\ref{fig:r_pe_cs5}. Our factors are scrambling (yes or no) and difficulty (easy or hard). The model chooses "easy" and "not scrambled" as the intercept value. Difficulty and scrambling show no significant factor value, while their interaction does. The base intercept is not significant meaning that the base error rate of the model may not be be reliably considered to lie above zero.', label='tab:r_pe_cs5s')}
	    \py[pe_cs3]{lm(data=data_pe_cs3[(data_pe_cs3['CoI'] == 'scrambling-11') | (data_pe_cs3['CoI'] == 'scrambling-23') | (data_pe_cs3['CoI'] == 'emotion-hard') | (data_pe_cs3['CoI'] == 'emotion-easy')], fixed='RT~difficulty*scrambled', random='ID', title='Mixed model fitted to the raw reaction time data depicted in figure~\\ref{fig:r_pe_cs3}. Our factors are scrambling (yes or no) and difficulty (easy or hard). The model chooses "easy" and "not scrambled" as the intercept value. The base intercept is significant, indicating reaction times of the model are above zero. The difficulty factor is also positive and significant meaning that difficulty adds to response latency. All other factors are not significantly other than zero.', label='tab:r_pe_cs3s')}
	    
	    We would like to point out that the null residual variance of our model indicates that it could be overparameterized.
	    We have tried a series of alternate models (“scrambled” and “difficulty” - not including interaction -, “scrambled” alone, and “difficulty” alone), but all resulted in null residual variance - 
	    see tables~\ref{tab:r_pe_cs5s1}, \ref{tab:r_pe_cs5s2}, and~\ref{tab:r_pe_cs5s3}.
	    
	    The reaction time model (table~\ref{tab:r_pe_cs3s}) paints a similar picture: with a significant value for the difficulty factor and no significance either for scrambling nor for scrambling and difficulty interaction.
	    We would conclude that in spite of our reduced sample sizes and aforementioned reproducibility issues our scrambling algorithm represents a viable type for a baseline (further discussion in section~\ref{sec:d_pe}.
	    
	    It should be noted that though not significantly different, both of these simple visual recognition reaction times undershoot their counterpart emotion recognition reaction times.
	    In light of this we have decided to use a \SI{6}{\pixel} kernel- and \SI{10}{\pixel} cluster-scrambled image baseline for difficult emotion recognition, 
	    and a \SI{6}{\pixel} kernel- and \SI{22}{\pixel} cluster-scrambled image baseline for easy emotion recognition.
	\subsection{Reaction Times}\label{sec:pe_d_rt}
	    Figure~\ref{fig:r_pe_ss1} confirms our assumption that reaction times for the difficult emotion recognition condition are significantly different from (one-tailed related sample t-test \textit{p}-value of 
	    \py[pe_ss1]{tex_nr(ttest_rel(data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 40)]['RT'], data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 100)]['RT'])[1]/2)}),
	    and higher than for the easy condition.
	    The overall results also support our assumption that there is a downward trend in reaction times over increasing scrambling cluster sizes.
	    Additionally, mainly in trials with simple cluster-based scrambling (section~\ref{sec:pe_r_ss} we see the emergence of a plateau-phase over higher scrambling cluster sizes.
	    
	    This plateau suggests that scrambling cluster sizes of \SI{14}{\pixel}, \SI{18}{\pixel}, \SI{22}{\pixel}, and \SI{26}{\pixel} seen in figure~\ref{fig:r_pe_ss1} possessed the same recognition-relevant quality, which the \SI{6}{\pixel} scrambling cluster - at least - did not.
	    If this purported feature is to explain the reaction time distribution, it should emerge at a scrambling cluster size of around \SI{10}{\pixel}.
	    Visual scrutiny of the images suggested that the emergent feature may be recognizable facial elements - more precisely the eyes (with the iris having an outer diameter of approximately \SI{8}{\pixel}).
	    
	    To test our hypothesis and define a more appropriate baseline for simple visual recognition, we devised a new set of experiments - described in section~\ref{sec:pe_m_si_cs}, and analyzed in section \ref{sec:pe_r_cs}.
	    An obvious feature there was the disappearance of the plateau phase, which supports our hypothesis regarding its emergence due to facial features with a horizontal and/or vertical spatial frequency of around \SI{8}{\pixel}.
	    This is - however - only partly corroborated by other composite scrambling test runs, as seen in supplementary figures~\ref{fig:r_pe_cs1} and~\ref{fig:r_pe_cs2}.
	    
	    In section~\ref{sec:pe_m_bt_cs} we have detailed our decision to settle for a \SI{4}{\second} reaction time window, the predicted ideal cropping being \pySI{np.around(data_pe_ss2['RT'].mean()+3*np.std(data_pe_ss2['RT']), decimals=2)}{\second}, as calculated in section~\ref{sec:pe_r_ss}.
	    In figure~\ref{fig:r_pe_cs4} we see that reaction times seem to fade approximately \SI{0.5}{\second} before our cut-off, and the fitted normal distribution does not indicate expected results beyond that point.
	    We take these results as confirmation that our selected cut-off time is not over-stringent for the selected conditions (easy and hard emotion recognition, plus visual recognition of scrambled images processed with a \SI{6}{\pixel} scrambling kernel and \SI{11}{\pixel} and \SI{23}{\pixel} scrambling cluster respectively).
	\subsection{Error Rates}
	    Our error rate distribution over categories proves difficult to interpret.
	    It is obvious for one thing that error rates for most categories vary greatly among participants.
	    A significant effect indicating that regardless of reaction times, difficult emotion recognition prompts a higher rate than all other conditions is documented under section~\ref{sec:pe_r_cs}.
	\subsection{Data Reliability}
	    As our sample sizes are reduced, we acknowledge the limited reliability with which we can make claims pertaining to the general population. 
	
	    We would, however, also like to indicate that both inter-trial and inter-participant variability is high (as seen in figure~\ref{fig:pe_r1}).
	    The accuracy of the determined mean (reflected by the standard errors of figure~\ref{fig:r_pe_cs3}) could be improved by more extensive testing - though the usefulness of doing so with respect to our search for an optimal baseline would be limited.
	    Regardless of the quality of our mean, reaction times on individual trials would still often coincide even for less stringent or sub-optimal choices of a baseline.  
	    This would happen on the trial level, as well as on the \textit{participant mean} level.
	    Please see the standard deviations in figure~\ref{fig:r_pe_cs3} for a graphical representation of where approximately \SI{68}{\percent} of data points reside for each condition.
