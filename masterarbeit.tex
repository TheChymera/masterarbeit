\input{header.tex}
\input{summary.tex}
\input{background.tex}
\input{methods.tex}
\chapter{Results}                                                                          
    \section{Preliminary Experiments}\label{sec:r_pe}
	In order to establish an experimental paradigm which affords the comparison between emotion and pattern recognition, we need to select stimuli whose matching is correspondingly difficult.
	For the emotion recognition trials, we decided on faces with emotional concentrations of 40\% and 100\% (as discussed in section~\ref{sec:m_vs_ef}).
	
	In the following experiments we examine reaction times and error rates for the recognition of progressively scrambled images in comparison to the recognition of our two emotional concentrations.

	\py[pe1]{fig_pe1}
	
	The reaction time figures which we present include both per-participant and population sample bar plots (the latter marked as “ALL”).
	As our sample sizes are reduced, we acknowledge the limited reliability with which we can make claims pertaining to the general population. 
	
	We would, however, also like to indicate that both inter-trial and inter-participant variability is high (as seen in figure~\ref{fig:r_pe1}).
	The accuracy of the determined mean (reflected by the standard errors in figure~\ref{fig:r_pe1}) could be improved by more extensive testing.
	However, reaction times on individual trials would still often coincide even for less stringent or sub-optimal choices of a baseline.  
	This would happen on the trial level, as well as on the \textit{mean} level for certain participants.
	Please see the standard deviations in figure~\ref{fig:r_pe1} for a graphical representation of where approximately \SI{68}{\percent} of data points reside for each condition.
	\subsection{Simple Cluster-Based Scrambling}\label{sec:r_pe_ss}
	    For the results presented in figure~\ref{fig:r_pe_ss1} we have used a simple cluster-based scrambling algorithm and a hand-written balanced stimulus sequence 
	    (both detailed in section~\ref{sec:m_pe_ss}).
	    \py[pe_ss1]{fig_pe_ss1}
	    
	    Figure~\ref{fig:r_pe_ss1} confirms our assumption that reaction times for the difficult emotion recognition condition are significantly different from (one-tailed related sample t-test \textit{p}-value of 
	    \py[pe_ss1]{tex_nr(ttest_rel(data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 40)]['RT'], data_pe_ss1[(data_pe_ss1['scrambling'] == 0) & (data_pe_ss1['intensity'] == 100)]['RT'])[1]/2)}),
	    and higher than for the easy condition.
	    The results also support our assumption of the presence of a downward trend in reaction times over increasing scrambling cluster sizes.
	    
	    To test the validity of this tentative interpretation, we have fitted a linear model to the reaction times of pattern recognition trials.
	    The model presented in table~\ref{tab:r_pe_ss1} supports our interpretation by showing that:
	    \begin{itemize}
		\item There is a negative progression among the first three factors, with all factor values lying outside of the confidence intervals of all others.
		\item For the subsequent 4 factors there is no obvious trend, with all factor values lying within each other's confidence intervals. 
	    \end{itemize}
	    \py[pe_ss1]{lm(data=data_pe_ss1[(data_pe_ss1['scrambling'] != 0)], fixed='RT~COI', random='ID', title='Linear model fitted to the raw data depicted in figure~\\ref{fig:r_pe_ss1}. Our factors are the conditions of interest (COI), excluding the emotion recognition trials. The mod el chooses the first factor (scrambling-06) as the base intercept. Note the downwards trend for the first 3 factors and that the last 4 factors\' values lie within each other\'s confidence intervals.', label='tab:r_pe_ss1')}

	    This plateau suggests that scrambling cluster sizes of \SI{14}{\pixel}, \SI{18}{\pixel}, \SI{22}{\pixel}, and \SI{26}{\pixel} possessed the same recognition-relevant quality, which the \SI{6}{\pixel} scrambling cluster - at least - did not.
	    If this purported feature is to explain the reaction time distribution, it should emerge at a scrambling cluster size of around \SI{10}{\pixel}.
	    Visual scrutiny of the images suggested that the emergent feature may be recognizable facial elements - more precisely the eyes (with pupil and iris having a diameter of approximately \SI{8}{\pixel}).
	    To test our hypothesis and define a more appropriate baseline for simple visual recognition, we devised a new set of experiments - described in section~\ref{sec:m_pe_cs}, and analyzed in section \ref{sec:r_pe_cs}.
	    
	    Though the images used in this first experiment run shall not be used as the definitive baseline, we conduct a baseline search to use for our further analysis in this section.
	    As we can see in table~\ref{tab:r_pe_ss2} pattern recognition of figures produced with a \SI{6}{\pixel} scrambling cluster recommends itself as the least unlikely (to keep with accurate terminology of the hypothesis testing we are performing) condition to share an equivalent baseline with difficult emotion recognition.
	    Similarly, it is pattern recognition of images processed with a \SI{22}{\pixel} scrambling cluster which we choose as our best-guess reaction time equivalent for easy emotion recognition.
	    \py[pe_ss1]{p_table(data_pe_ss1, ['COI', 'emotion-easy', 'emotion-hard'], ['scrambling', 6, 10, 14, 18, 22, 26], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Two-tailed paired sample t-test \\textit{p}-values for the data in figure~\\ref{fig:r_pe_ss1}; testing the probability of our measured observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_ss2')}
	    
	    In addition to the reaction time per-category analysis, we attempted to gauge the maximal window for reaction times which we should provide in further experiments.
	    For this analysis we have selectively looked at reaction times for images processed with \SI{0}{\pixel}, \SI{6}{\pixel}, and \SI{22}{\pixel} scrambling clusters (due to considerations detailed above and documented in table~\ref{tab:r_pe_ss2}).
	    \py{fig_pe_ss2}
	    
	    Figure~\ref{fig:r_pe_ss2} shows the reaction time distribution for the said subset of trials.
	    The mean value ($\mu$) for the reaction times is approximately \pySI{np.around(data_pe_ss2['RT'].mean(), decimals=2)}{\second}, 
	    and the standard deviation ($\sigma$) of the fitted normal distribution is approximately \pySI{np.around(np.std(data_pe_ss2['RT']), decimals=2)}{\second}.
	    Based on the three-sigma rule (see figure~\ref{eq:3s} for a general expression) we have decided that a reaction time cut-off of \pySI{np.around(data_pe_ss2['RT'].mean()+3*np.std(data_pe_ss2['RT']), decimals=2)}{\second} should not statistically distort our data.
	    
	    We have also tried to analyse the error rates in our Hariri-style matching task in order to extract more information on the appropriateness of our proposed baselines.
	    The results herefor are presented in figure~\ref{fig:r_pe_ss3}.
	    \py[pe_ss3]{fig_pe_ss3}

	    Our error rate distribution over categories proves difficult to interpret.
	    It is obvious for one thing that error rates for most categories vary greatly among participants.
	    It also seems possible that emotion recognition in easy trials may be more robust than image matching in all other categories (owing to the robust null rate).
	    \py[pe_ss3]{av(data_pe_ss3, 'ER~COI+Error(ID)', title='One-way repeated measure ANOVA table for the data depicted in figure~\\ref{fig:r_pe_ss3}. The $Pr(>F)$ value indicates the probability of our results occurring by chance if the means of our defined categories are equal.', label='tab:r_pe_ss3')}
	    
	    To test this assumption we have performed an ANOVA (see table~\ref{tab:r_pe_ss3}).
	    The results of this analysis prove equally difficult to interpret. While the $Pr(>F)$ (nominally, \textit{p}) value lies above the popular significance threshold of \textit{p}<0.05, 
	    it is still below the more lax - though not unheard of - \textit{p}<0.1 threshold.
	    
	    To further document this analysis we have fitted a linear model with computed \textit{p}-values (see table~\ref{tab:r_pe_ss3a}).
	    This model indicates that while there are !!!
	    \py[pe_ss3]{lm(data_pe_ss3, fixed='ER~COI', random='ID', title='figure~\\ref{fig:r_pe_ss1}', label='tab:r_pe_ss3a', model='nlme')}

	    This could raise doubts about our choice of baseline, and should be kept in mind for further scrutiny (continued in the discussion of figure~\ref{fig:r_pe_cs5}).
	\subsection{Composite (Kernel-and-Cluster-Based) Scrambling}\label{sec:r_pe_cs}
	    Based on the results detailed in section ~\ref{sec:r_pe_ss} we have performed additional experiments using a series of improved method choices (detailed in section \ref{sec:m_pe_cs}).
	    \py{fig_pe_cs1}
	    
	    Figure~\ref{fig:r_pe_cs1} presents the the data from the first run of these experiments.
	    An obvious feature here is the disappearance of the plateau phase, which supports our hypothesis regarding its emergence due to facial features with a horizontal and/or vertical spatial frequency of around \SI{8}{\pixel} (formulated in section~\ref{sec:r_pe_ss}).
	    
	    We have tried to determine the best-guess equivalent in terms of reaction times for our categories of interest using a t-test \textit{p}-value listing (see table~\ref{tab:r_pe_cs1}).
	    Our results indicate that pattern recognition of figures produced with a \SI{11}{\pixel} scrambling cluster is the least unlikely condition to share an equivalent baseline with difficult emotion recognition.
	    Similarly, it is pattern recognition of images processed with a \SI{23}{\pixel} scrambling cluster which we choose as our best-guess reaction time equivalent for easy emotion recognition.
	    \py{p_table(data_pe_cs1, ['COI', 'emotion-easy', 'emotion-hard'], ['scrambling', 11, 15, 19, 23, 27], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Table of two-tailed paired sample t-test \\textit{p}-values for the data in figure ~\\ref{fig:r_pe_cs1}, testing the probability of our observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_cs1')}
	    
	    It is somewhat concerning that the \textit{p}-value of our best difficult emotion recognition match (\py{tex_nr(ttest_rel(data_pe_cs1[(data_pe_cs1['scrambling'] == 0) & (data_pe_cs1['intensity'] == 40)].groupby('ID')['RT'].mean(), data_pe_cs1[(data_pe_cs1['scrambling'] == 11)].groupby('ID')['RT'].mean())[1])}) is considerably higher than what we have obtained in section~\ref{sec:r_pe_ss}.
	    
	    We assume that individual variability of our small sample of participants may be responsible for this irregularity.
	    In an effort to make a more accurate prediction we have re-run the experiment with slightly different (and lower) scrambling clusters.
	    \py{fig_pe_cs2}
	    
	    We present the new data in figure~\ref{fig:r_pe_cs2}.
	    The results from this re-run are curious in that they mostly do not corroborate our findings from the previous run (figure~\ref{fig:r_pe_cs1}).
	    The data does seem to indicate a more appropriate baseline for hard emotion recognition (namely visual recognition of pictures processed with a scrambling kernel of \SI{6}{\pixel} and a scrambling cluster of \SI{10}{\pixel} - two-tailed \textit{p} = \py{tex_nr(ttest_rel(data_pe_cs2[(data_pe_cs2['scrambling'] == 0) & (data_pe_cs2['intensity'] == 40)].groupby('ID')['RT'].mean(), data_pe_cs2[(data_pe_cs2['scrambling'] == 10)].groupby('ID')['RT'].mean())[1])}, see table~\ref{tab:r_pe_cs2} for the full comparison).
	    However, pattern recognition conditions with as little as \SI{1}{\pixel} cluster scrambling difference between them show a notable - though strictly speaking not significant - difference in reaction times in this run compared to the one before
	    (figure~\ref{fig:r_pe_cs2}'s \SI{10}{\pixel} vs. figure~\ref{fig:r_pe_cs1}'s \SI{11}{\pixel}: two-tailed unpaired t-test \textit{p}-value of  
	    \py{tex_nr(ttest_ind(data_pe_cs2[(data_pe_cs2['scrambling'] == 10)].groupby('ID')['RT'].mean(), data_pe_cs1[(data_pe_cs1['scrambling'] == 11)].groupby('ID')['RT'].mean())[1])}). 
	    \py{p_table(data_pe_cs2, ['COI', 'emotion-easy', 'emotion-hard'], ['scrambling', 6, 10, 14, 18, 22], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Table of two-tailed paired sample t-test \\textit{p}-values for the data in figure ~\\ref{fig:r_pe_cs2}, testing the probability of our observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_cs2')}
	    
	    The emergence of a reaction time plateau for larger scrambling clusters (previously observed in section~\ref{sec:r_pe_ss}; analogous linear model shown under table~\ref{tab:r_pe_cs2a}) raises further questions.
	    \py{lm(data=data_pe_cs2[(data_pe_cs2['scrambling'] != 0)], fixed='RT~COI', random='ID', title='Linear model fitted to the raw data depicted in figure~\\ref{tab:r_pe_cs2a}. Our factors are the conditions of interest (COI), excluding the emotion recognition trials. The model chooses the first factor (scrambling-06) as the base intercept. Note the downwards trend for the first 3 factors and that the last 3 factors\' values land confidence intervals are almost identical.', label='tab:r_pe_cs2a')}
	    
	    We believe that this variability is - again - due to our reduced and varying participant sample, and that this merits even further investigation.
	    Concomitantly to this realization we have also decided to adapt the size of the visual window to accurately match the degrees of visual angle which our participants would be seeing in our fMRI-monitor set-up. This is a slight decrease in size from the trials above: u = \SI{4.24}{\degree} now versus u $\approx$ \SI{6}{\degree} earlier (with “u” denoting face image height) -
	    further technical clarification is available under section~\ref{sec:m_bt}.
	    
	    This third run of our experiment (with results depicted in figure~\ref{fig:r_pe_cs3}) should be the best approximation for the visual input the participants will be receiving in the fMRI trials.
	    We therefore trust this run above all others as a guideline for further experimental design choices.
	    \py[pe_cs3]{fig_pe_cs3}
	    
	    Figure~\ref{fig:r_pe_cs3} shows a linear decay of reaction times over increasing scrambling cluster size
	    (as opposed to a plateau for larger scrambling clusters, which we had noticed in some of the previous runs).
	    The data recommends pictures scrambled with a kernel of \SI{6}{\pixel} and a cluster of \SI{11}{\pixel} as an appropriate baseline for hard emotion recognition
	    and pictures scrambled with a kernel of \SI{6}{\pixel} and a cluster of \SI{23}{\pixel} as an appropriate baseline for easy emotion recognition
	    (for the \textit{p}-value listing, see table~\ref{tab:r_pe_cs3}).
	    It should be noted that though not significantly different, both of these simple visual recognition reaction times undershoot their counterpart emotion recognition reaction times.
	    In light of this we have decided to use a \SI{6}{\pixel} kernel- and \SI{10}{\pixel} cluster-scrambled image baseline for difficult emotion recognition, 
	    and a \SI{6}{\pixel} kernel- and \SI{22}{\pixel} cluster-scrambled image baseline for easy emotion recognition.
	    \py[pe_cs3]{p_table(data_pe_cs3, ['COI', 'emotion-easy', 'emotion-hard'], ['scrambling', 11, 15, 19, 23, 27], refcap='Proposed best estimators (scrambling cluster sizes in \\SI{}{px})', caption='Table of two-tailed paired sample t-test \\textit{p}-values for the data in figure ~\\ref{fig:r_pe_cs3}, testing the probability of our observations if the compared conditions share the same mean. Note that - though unorthodox - this test does not lose accuracy due to multiple comparisons. As we are looking for the group least likely to reject the null hypothesis, multiple comparison actually makes the test more stringent.', label='tab:r_pe_cs3')}
	    \py[pe_cs5]{fig_pe_cs5}
	    
	    To re-examine our doubts on the suitability of our baseline concept (raised in section~\ref{sec:r_pe_ss}), we have also examined error rates for this last and methodologically most faithful preliminary experiment run.
	    Figure~\ref{fig:r_pe_cs5} presents a slightly divergent picture from what we have seen in figure~\ref{fig:r_pe_ss3}.
	    For one thing, the easy emotion recognition condition no longer has a null error rate.
	    This time, however, there is a significant error rate divergence for one of our conditions compared to all of the others (as seen in figure~\ref{fig:r_pe_cs5}, and verified in table~\ref{tab:r_pe_cs5}).
	    \py[pe_cs5]{av(data_pe_cs5, 'ER~COI+Error(ID)', title='One-way repeated measure ANOVA table for the data depicted in figure~\\ref{fig:r_pe_cs5}. The $Pr(>F)$ value indicates the probability of our results occurring by chance if the means of our defined categories are equal.', label='tab:r_pe_cs5')}
	
	    While this finding confirms limited reliability for all of our our preliminary trials, possible doubts that our baseline may be unsuited due to differing error rates should also be treated with according scepticism.
	    
	    Reproducibility issues apparent in the data presented in this section - along with broader conclusions to be drawn from these experiments - are further discussed in section \ref{sec:d_pe}.
	    
	\subsection{Final Model Quality Assessment}
	    We have decided to perform a number of tests to check the quality of the baseline we have proposed as the best-guess solution based on the data detailed above.
	    
	    First we analyse whether our slightly over-cropped reaction time window seems to distort our data.
	    In section~\ref{sec:m_pe_cs} we have detailed our decision to settle for a \SI{4}{\second} reaction time window, the predicted ideal cropping being \pySI{np.around(data_pe_ss2['RT'].mean()+3*np.std(data_pe_ss2['RT']), decimals=2)}{\second}, as calculated in section~\ref{sec:r_pe_ss}.
	    In figure~\ref{fig:r_pe_cs4} we see that reaction times seem to fade approximately \SI{0.5}{\second} before our cut-off, and the fitted normal distribution does not indicate expected results beyond that point.
	    We take these results as confirmation that our selected cut-off time is not over-stringent for the selected conditions (easy and hard emotion recognition, plus visual recognition of scrambled images processed with a \SI{6}{\pixel} kernel and \SI{11}{\pixel} and \SI{23}{\pixel} cluster respectively).	    
	    \py[pe_cs4]{fig_pe_cs4}
	    
	    Additionally we are fitting a mixed model to both the reaction times and error rates of our last-run data.
	    For this model we are defining “scrambling” and “difficulty” as our factors of interest (independent variables).
	    Easy emotion recognition and its corresponding pattern recognition variant (\SI{6}{\pixel} kernel- and \SI{23}{\pixel} cluster-scrambled) are defined as easy,
	    while hard emotion recognition and its corresponding pattern recognition variant (\SI{6}{\pixel} kernel- and \SI{11}{\pixel} cluster-scrambled) are defined as hard.
	    
	    For our ideal baseline we would be expecting a null value for the scrambling factor and a positive value for the difficulty factor in the reaction time model.
	    In the error rate model we would be expecting a null value for the scrambling factor and either a null or positive value for the difficulty factor.
	    
	    Tables~\ref{tab:r_pe_cs5s} and~\ref{tab:r_pe_cs3s}, provide a succinct and reliable validation for our proposed baseline model.
	    
	    Table~\ref{tab:r_pe_cs5s} recommends the choice of scrambling as a suitable baseline creation method for our task.
	    The factor determined for this dimension is null, meaning that scrambling does not compromise the behavioural equivalence of emotional testing and baseline trials.
	    Difficulty does also not seem to impact the error rate, which we consider fortunate, though a higher error rate for difficult trials would also have been acceptable.
	    The interaction effect of difficulty and scrambling is probably an effect of the deviating hard emotion recognition category we have observed under figure~\ref{fig:fig_pe_cs5}, with an inverted balance due to our model's choice of a base intercept.
	    We would like to point out that the null residual variance of our model indicates that it could be overparameterized.
	    We have tried a series of alternate models (“scrambled” and “difficulty” - not including interaction -, “scrambled” alone and “difficulty” alone), but all resulted in null residual variance - 
	    see tables~\ref{tab:r_pe_cs5s1}, \ref{tab:r_pe_cs5s1}, and~\ref{tab:r_pe_cs5s1}.
	    
	    The reaction time model (table~\ref{tab:r_pe_cs3s}) paints a similar picture: with a significant value for the difficulty factor and no significance either for scrambling nor for scrambling and difficulty interaction.
	    We would conclude that in spite of our reduced sample sizes and aforementioned reproducibility issues our scrambling algorithm represents a viable choice of baseline (further discussion in section~\ref{sec:d_pe}.
	    
	    \py[pe_cs5]{lm(data=data_pe_cs5[(data_pe_cs5['COI'] == 'scrambling-11') | (data_pe_cs5['COI'] == 'scrambling-23') | (data_pe_cs5['COI'] == 'emotion-hard') | (data_pe_cs5['COI'] == 'emotion-easy')], fixed='ER~difficulty*scrambled', random='ID', title='Linear model fitted to the raw error rate data depicted in figure~\\ref{fig:r_pe_cs5}. Our factors are scrambling (yes or no) and difficulty (easy or hard). The model chooses "easy" and "not scrambled" as the intercept value. Difficulty and scrambling show no significant factor value, while their interaction does. The base intercept is not significant meaning that the base error rate of the model may not be be reliably considered to lie above zero.', label='tab:r_pe_cs5s')}
	    \py[pe_cs3]{lm(data=data_pe_cs3[(data_pe_cs3['COI'] == 'scrambling-11') | (data_pe_cs3['COI'] == 'scrambling-23') | (data_pe_cs3['COI'] == 'emotion-hard') | (data_pe_cs3['COI'] == 'emotion-easy')], fixed='RT~difficulty*scrambled', random='ID', title='Linear model fitted to the raw reaction time data depicted in figure~\\ref{fig:r_pe_cs3}. Our factors are scrambling (yes or no) and difficulty (easy or hard). The model chooses "easy" and "not scrambled" as the intercept value. The base intercept is significant, indicating reaction times of the model are above zero. The difficulty factor is also positive and significant meaning that difficulty adds to response latency. All other factors are not significantly other than zero.', label='tab:r_pe_cs3s')}
	    
\chapter{Discussion}
    \section{Preliminary Experiments}\label{sec:d_pe}
	Most conclusions drawn from our preliminary experiments (for instance in section~\ref{sec:m_pe_cs} or section~\ref{sec:r_pe_cs}) are only marginally reliable due to the high inter-run variability noticed throughout section~\ref{sec:r_pe}.
	We believe the chief reason for this is our reduced participant sample (n = 6 to 7), and we would recommend a more thorough examination on a larger population to better support any claims pertaining to accurate reaction time and error rate comparisons.
	
	Some hallmarks, however, have been constant over all our runs, and we believe these deserve to be reported with more pronounced certainty.
	\subsection{Reaction Times over Scrambling Cluster Sizes}
	    Our preliminary experiments show that even when confronted with very high variability in results there is a robust decay of reaction times as scrambling cluster sizes increase. 
\chapter{Meta}
    \begin{figure}[H]
	\[ \sigma_{x,y} = \sqrt{\sigma_{x}^{2}+\sigma_{y}^{2}} = \sqrt{2\sigma_{x}^{2}} \approx \sqrt{2 \cdot (0.68 K)^{2}} \approx 0.96K\]
	\caption{Here we calculate the standard deviation ($\sigma$) of the distance from the original pixel location to the new pixel location following kernel-based scrambling, as detailed in section~\ref{sec:m_vs_si_kbs}. The standard deviation along one axis is defined as $0.68K$ (\SI{68}{\percent} of the scrambling kernel, $K$) following the 68–95–99.7 rule, though experimentally we have found slightly lower values ($\approx 0.6K$).}
	\label{eq:lrgn}
    \end{figure}
    \begin{figure}[H]
	\[\Pr(\mu - \sigma \le x \le \mu + \sigma) \approx 0.6827 \]
	\[\Pr(\mu - 2\sigma \le x \le \mu + 2\sigma) \approx 0.9545 \]
	\[\Pr(\mu - 3\sigma \le x \le \mu + 3\sigma) \approx 0.9973 \]
	\caption{The general expression of the three-sigma rule, in mathematical notation, for $x$ being an observation from a normally distributed random variable, $\mu$ being the mean of the distribution, and $\sigma$ being its standard deviation. The three-sigma rule (also known as the “68–95–99.7 rule”) states that nearly all values lie within 3 standard deviations of the mean in a normal distribution.}
	\label{eq:3s}
    \end{figure}
    \begin{figure}[H]
	\begin{eqnarray*}
	    A(h)&=&\frac{R^2}{2}\left[2\arccos\left(1-\frac{h}{R}\right) - \sin\left(2 \arccos\left(1-\frac{h}{R}\right)\right) \right]\\
	    &=&R^2 \left [\arccos{\left (1-\frac{h}{R}\right)} - \left (1-\frac{h}{R}\right) \sqrt{2 \frac{h}{R} - \frac{h^2}{R^2}} \right]
	\end{eqnarray*}
	\caption{The area of a circle segment $A$ defined relative to the height of that segment, $h$ - with $R$ as the circle radius. We use this as a function for how much of the pupil area will be lost relative to how far an eyelid covers it. For the sake of simplicity we approximate the eyelid with a straight rather than very slightly curved line.}
	\label{eq:cs}
    \end{figure}
    \py[pe_cs5]{lm(data=data_pe_cs5[(data_pe_cs5['COI'] == 'scrambling-11') | (data_pe_cs5['COI'] == 'scrambling-23') | (data_pe_cs5['COI'] == 'emotion-hard') | (data_pe_cs5['COI'] == 'emotion-easy')], fixed='ER~difficulty+scrambled', random='ID', title='Linear model fitted to the raw error rate data depicted in figure~\\ref{fig:r_pe_cs5}. Our factors are scrambling (yes or no) and difficulty (easy or hard) - not including their interaction. The model chooses "easy" and "not scrambled" as the intercept value.', label='tab:r_pe_cs5s1')}
    \py[pe_cs5]{lm(data=data_pe_cs5[(data_pe_cs5['COI'] == 'scrambling-11') | (data_pe_cs5['COI'] == 'scrambling-23') | (data_pe_cs5['COI'] == 'emotion-hard') | (data_pe_cs5['COI'] == 'emotion-easy')], fixed='ER~difficulty', random='ID', title='Linear model fitted to the raw error rate data depicted in figure~\\ref{fig:r_pe_cs5}. Our factor is and difficulty (easy or hard). The model chooses "easy" as the intercept value', label='tab:r_pe_cs5s2')}
    \py[pe_cs5]{lm(data=data_pe_cs5[(data_pe_cs5['COI'] == 'scrambling-11') | (data_pe_cs5['COI'] == 'scrambling-23') | (data_pe_cs5['COI'] == 'emotion-hard') | (data_pe_cs5['COI'] == 'emotion-easy')], fixed='ER~scrambled', random='ID', title='Linear model fitted to the raw error rate data depicted in figure~\\ref{fig:r_pe_cs5}. Our factors are scrambling (yes or no). The model chooses "not scrambled" as the intercept value.', label='tab:r_pe_cs5s3')}

    

\chapter{Acknowledgements}
    In addition to the faculty advisers mentioned in the preamble of this document, we would like to explicitly give thanks to a number of other members of the department of clinical psychology at the Central Institute of Mental Health in Mannheim.
    Their expertise in designing and performing experiments, and analysing results was instrumental to the success of this thesis.
    \begin{multicols}{2}
	\begin{itemize}
	    \item Martin Gerchen
	    \item Daniela Mier
	    \item Carina Sauer
	    \item Gabriela Stoessel
	\end{itemize}
    \end{multicols}
    \vspace{0.5cm}
    We would also like to extend our gratitude to the numerous other people with whom we have interacted in the process of writing this thesis, and whose goodwill and effort made a significant difference pertaining to the quality of this work.
    \begin{itemize}
	\item Øystein Bjørndal, of the Norwegian Defence Research Establishment
	\item Ben Bolker, of McMaster University
        \item Denis A. Engemann, of the Juelich Research Centre in Cologne
	\item Laurent Gautier, of the Technical University of Denmark
	\item Marek Hlavac, of Harvard University
	\item Philip Leifeld, of the University of Konstanz
	\item Christopher Louden, of the University of Texas
	\item Geoffrey M. Poore, of Union University
    \end{itemize}
\input{footer.tex}
